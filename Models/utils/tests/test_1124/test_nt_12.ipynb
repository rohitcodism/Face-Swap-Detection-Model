{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\anaconda3\\envs\\Face-Swap-Detection-Model\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\USER\\anaconda3\\envs\\Face-Swap-Detection-Model\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datamaker_f import VideoDataGenerator, VideoDataGenerator2\n",
    "from pipeline_f import build_full_model\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the pickle file\n",
    "with open(\"F:/video_data_nt_16K.pkl\", \"rb\") as f:\n",
    "    pickled_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample video '000' structure:\n",
      "Frames count: 25\n",
      "Frames labels count: 25\n",
      "Micro-expression count: 75\n",
      "Micro-expression labels count: 75\n"
     ]
    }
   ],
   "source": [
    "# Print the structure of one sample entry\n",
    "sample_video = list(pickled_data.keys())[0]  # Take the first video folder as an example\n",
    "print(f\"Sample video '{sample_video}' structure:\")\n",
    "print(\"Frames count:\", len(pickled_data[sample_video]['frames']))\n",
    "print(\"Frames labels count:\", len(pickled_data[sample_video]['frame_label']))\n",
    "print(\"Micro-expression count:\", len(pickled_data[sample_video]['Micro_Expression']))\n",
    "print(\"Micro-expression labels count:\", len(pickled_data[sample_video]['Micro_Expression_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_names, labels = zip(*[\n",
    "    (video_name, video_info['frame_label'][0])\n",
    "    for video_name, video_info in pickled_data.items()\n",
    "    if 'frame_label' in video_info and len(video_info['frame_label']) > 0\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_names, test_names, train_labels, test_labels = train_test_split(video_names, labels, test_size=0.3, random_state=42)\n",
    "train_names, val_names, train_labels, val_labels = train_test_split(train_names, train_labels, test_size=0.2, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dictionaries for each split\n",
    "train_data = {name: pickled_data[name] for name in train_names}\n",
    "val_data = {name: pickled_data[name] for name in val_names}\n",
    "test_data = {name: pickled_data[name] for name in test_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8940\n",
      "2236\n",
      "4791\n"
     ]
    }
   ],
   "source": [
    "#length of train and test data\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output signature for the generator\n",
    "output_signature = (\n",
    "    (\n",
    "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32)\n",
    "    ),\n",
    "    tf.TensorSpec(shape=(None,1), dtype=tf.float32)\n",
    ")\n",
    "\n",
    "train_generator = tf.data.Dataset.from_generator(\n",
    "    lambda: VideoDataGenerator(train_data),\n",
    "    output_signature=output_signature\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = tf.data.Dataset.from_generator(\n",
    "    lambda: VideoDataGenerator(val_data),\n",
    "    output_signature=output_signature\n",
    ")\n",
    "\n",
    "test_generator = tf.data.Dataset.from_generator(\n",
    "    lambda: VideoDataGenerator(test_data),\n",
    "    output_signature=output_signature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Distribution: {0.0: 4449, 1.0: 4491}\n",
      "Validation Data Distribution: {0.0: 1106, 1.0: 1130}\n",
      "Testing Data Distribution: {0.0: 2412, 1.0: 2379}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_classes_tf_dataset(dataset):\n",
    "    counts = {}\n",
    "    \n",
    "    for batch_X, batch_y in dataset:\n",
    "        # Convert batch_y to numpy for counting\n",
    "        batch_y = batch_y.numpy()\n",
    "        unique, counts_batch = np.unique(batch_y, return_counts=True)\n",
    "        for u, c in zip(unique, counts_batch):\n",
    "            counts[u] = counts.get(u, 0) + c\n",
    "    \n",
    "    return counts\n",
    "\n",
    "# Example for train, val, and test datasets\n",
    "train_counts = count_classes_tf_dataset(train_generator)\n",
    "val_counts = count_classes_tf_dataset(val_generator)\n",
    "test_counts = count_classes_tf_dataset(test_generator)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training Data Distribution:\", train_counts)\n",
    "print(\"Validation Data Distribution:\", val_counts)\n",
    "print(\"Testing Data Distribution:\", test_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_frames shape: (16, 224, 224, 3)\n",
      "X_micro_exp shape: (16, 64, 64, 3)\n",
      "y shape: (16, 1)\n",
      "X_frames shape: (16, 224, 224, 3)\n",
      "X_micro_exp shape: (16, 64, 64, 3)\n",
      "y shape: (16, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_frame_0 type: <class 'numpy.ndarray'>, dtype: uint8\n",
      "sample_micro_exp_0 type: <class 'numpy.ndarray'>, dtype: uint8\n",
      "sample_frame_0 shape: (224, 224, 3)\n",
      "sample_micro_exp_0 shape: (64, 64, 3)\n",
      "sample_frame_1 type: <class 'numpy.ndarray'>, dtype: uint8\n",
      "sample_micro_exp_1 type: <class 'numpy.ndarray'>, dtype: uint8\n",
      "sample_frame_1 shape: (224, 224, 3)\n",
      "sample_micro_exp_1 shape: (64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize flags to track if we've found samples of each class\n",
    "found_label_0 = False\n",
    "found_label_1 = False\n",
    "\n",
    "# Initialize placeholders for samples\n",
    "sample_frame_0 = None\n",
    "sample_micro_exp_0 = None\n",
    "sample_frame_1 = None\n",
    "sample_micro_exp_1 = None\n",
    "\n",
    "# Take a batch and unpack it\n",
    "for batch in train_generator.take(2):\n",
    "    (X_frames, X_micro_exp), y = batch\n",
    "\n",
    "    # Print the shapes to verify\n",
    "    print(f\"X_frames shape: {X_frames.shape}\")\n",
    "    print(f\"X_micro_exp shape: {X_micro_exp.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "\n",
    "    # Loop through the batch to find examples of both labels\n",
    "    for sample_index in range(len(y)):\n",
    "        sample_label = int(y[sample_index].numpy()[0])  # Assuming binary classification\n",
    "\n",
    "        # Check if we already have examples for each label\n",
    "        if sample_label == 0 and not found_label_0:\n",
    "            found_label_0 = True\n",
    "            sample_frame_0 = X_frames[sample_index].numpy()\n",
    "            sample_micro_exp_0 = X_micro_exp[sample_index].numpy()\n",
    "\n",
    "        elif sample_label == 1 and not found_label_1:\n",
    "            found_label_1 = True\n",
    "            sample_frame_1 = X_frames[sample_index].numpy()\n",
    "            sample_micro_exp_1 = X_micro_exp[sample_index].numpy()\n",
    "\n",
    "        # Break loop once we have both examples\n",
    "        if found_label_0 and found_label_1:\n",
    "            break\n",
    "\n",
    "# Ensure the data is not None before processing\n",
    "if sample_frame_0 is not None and sample_micro_exp_0 is not None:\n",
    "    sample_frame_0 = sample_frame_0.astype(\"uint8\")\n",
    "    sample_micro_exp_0 = sample_micro_exp_0.astype(\"uint8\")\n",
    "else:\n",
    "    print(\"Warning: Label 0 data not found in the batch.\")\n",
    "\n",
    "if sample_frame_1 is not None and sample_micro_exp_1 is not None:\n",
    "    sample_frame_1 = sample_frame_1.astype(\"uint8\")\n",
    "    sample_micro_exp_1 = sample_micro_exp_1.astype(\"uint8\")\n",
    "else:\n",
    "    print(\"Warning: Label 1 data not found in the batch.\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "if sample_frame_0 is not None and sample_micro_exp_0 is not None:\n",
    "    # Display facial and micro-expression frames for label 0\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(sample_frame_0)\n",
    "    plt.title(\"Facial Frame | Label: 0\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(sample_micro_exp_0)\n",
    "    plt.title(\"Micro-Expression | Label: 0\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "if sample_frame_1 is not None and sample_micro_exp_1 is not None:\n",
    "    # Display facial and micro-expression frames for label 1\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(sample_frame_1)\n",
    "    plt.title(\"Facial Frame | Label: 1\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(sample_micro_exp_1)\n",
    "    plt.title(\"Micro-Expression | Label: 1\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the final details\n",
    "if sample_frame_0 is not None and sample_micro_exp_0 is not None:\n",
    "    print(f\"sample_frame_0 type: {type(sample_frame_0)}, dtype: {sample_frame_0.dtype}\")\n",
    "    print(f\"sample_micro_exp_0 type: {type(sample_micro_exp_0)}, dtype: {sample_micro_exp_0.dtype}\")\n",
    "    print(f\"sample_frame_0 shape: {sample_frame_0.shape}\")\n",
    "    print(f\"sample_micro_exp_0 shape: {sample_micro_exp_0.shape}\")\n",
    "\n",
    "if sample_frame_1 is not None and sample_micro_exp_1 is not None:\n",
    "    print(f\"sample_frame_1 type: {type(sample_frame_1)}, dtype: {sample_frame_1.dtype}\")\n",
    "    print(f\"sample_micro_exp_1 type: {type(sample_micro_exp_1)}, dtype: {sample_micro_exp_1.dtype}\")\n",
    "    print(f\"sample_frame_1 shape: {sample_frame_1.shape}\")\n",
    "    print(f\"sample_micro_exp_1 shape: {sample_micro_exp_1.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    min_lr=5e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\anaconda3\\envs\\Face-Swap-Detection-Model\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_full_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"full_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " spatial_feature_extractor   (None, 2048)                 2358771   ['input_7[0][0]']             \n",
      " (Functional)                                             2                                       \n",
      "                                                                                                  \n",
      " micro_exp_spatial_feature_  (None, 128)                  2224448   ['input_8[0][0]']             \n",
      " extractor (Functional)                                                                           \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)           (None, 1, 2048)              0         ['spatial_feature_extractor[1]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)           (None, 1, 128)               0         ['micro_exp_spatial_feature_ex\n",
      "                                                                    tractor[1][0]']               \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)           (None, 1, 2048)              0         ['spatial_feature_extractor[1]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)           (None, 30, 2048)             0         ['lambda_2[1][0]']            \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)           (None, 1, 128)               0         ['micro_exp_spatial_feature_ex\n",
      "                                                                    tractor[1][0]']               \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)           (None, 30, 128)              0         ['lambda_4[1][0]']            \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)           (None, 30, 2048)             0         ['lambda_6[1][0]']            \n",
      "                                                                                                  \n",
      " temporal_feature_extractor  (None, 30, 128)              2393600   ['lambda_3[1][0]']            \n",
      "  (Functional)                                                                                    \n",
      "                                                                                                  \n",
      " lambda_9 (Lambda)           (None, 30, 128)              0         ['lambda_8[1][0]']            \n",
      "                                                                                                  \n",
      " micro_exp_temporal_feature  (None, 30, 128)              427520    ['lambda_5[1][0]']            \n",
      " _extractor (Functional)                                                                          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 30, 2432)             0         ['lambda_7[1][0]',            \n",
      "                                                                     'temporal_feature_extractor[1\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'lambda_9[1][0]',            \n",
      "                                                                     'micro_exp_temporal_feature_e\n",
      "                                                                    xtractor[1][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 2432)                 0         ['concatenate[1][0]']         \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 256)                  622848    ['global_average_pooling1d[1][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 256)                  0         ['dense_2[1][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  32896     ['dropout_4[1][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 128)                  0         ['dense_3[1][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 64)                   8256      ['dropout_5[1][0]']           \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 64)                   0         ['dense_4[1][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    65        ['dropout_6[1][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29297345 (111.76 MB)\n",
      "Trainable params: 29243777 (111.56 MB)\n",
      "Non-trainable params: 53568 (209.25 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From c:\\Users\\USER\\anaconda3\\envs\\Face-Swap-Detection-Model\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\USER\\anaconda3\\envs\\Face-Swap-Detection-Model\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "    423/Unknown - 978s 2s/step - loss: 0.9175 - accuracy: 0.5121"
     ]
    }
   ],
   "source": [
    "history_df = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=1000,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 190s 633ms/step - loss: 0.6481 - accuracy: 0.7055\n",
      "Test loss: 0.6481104493141174, Test accuracy: 0.705489456653595\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Face-Swap-Detection-Model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
