{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\anaconda3\\envs\\Face-Swap-Detection-Model\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datamaker_f import VideoDataGenerator\n",
    "from pipeline_f import build_full_model\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from pkl_to_tfr import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_data = create_dataset('D:/Projects/Face-Swap-Detection-TFRecords/DF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkl_to_tfr import inspect_tfrecord_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_tfrecord_data(tfr_data, num_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_names, test_names, train_labels, test_labels = train_test_split(video_names, labels, test_size=0.3, random_state=42)\n",
    "train_names, val_names, train_labels, val_labels = train_test_split(train_names, train_labels, test_size=0.2, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dictionaries for each split\n",
    "train_data = {name: pickled_data[name] for name in train_names}\n",
    "val_data = {name: pickled_data[name] for name in val_names}\n",
    "test_data = {name: pickled_data[name] for name in test_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of train and test data\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output signature for the generator\n",
    "output_signature = (\n",
    "    (\n",
    "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32)\n",
    "    ),\n",
    "    tf.TensorSpec(shape=(None,1), dtype=tf.float32)\n",
    ")\n",
    "\n",
    "train_generator = tf.data.Dataset.from_generator(\n",
    "    lambda: VideoDataGenerator(train_data),\n",
    "    output_signature=output_signature\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = tf.data.Dataset.from_generator(\n",
    "    lambda: VideoDataGenerator(val_data),\n",
    "    output_signature=output_signature\n",
    ")\n",
    "\n",
    "test_generator = tf.data.Dataset.from_generator(\n",
    "    lambda: VideoDataGenerator(test_data),\n",
    "    output_signature=output_signature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize flags to track if we've found samples of each class\n",
    "found_label_0 = False\n",
    "found_label_1 = False\n",
    "\n",
    "# Take a batch and unpack it\n",
    "for batch in train_generator.take(1):\n",
    "    (X_frames, X_micro_exp), y = batch\n",
    "\n",
    "    # Print the shapes to verify\n",
    "    print(f\"X_frames shape: {X_frames.shape}\")\n",
    "    print(f\"X_micro_exp shape: {X_micro_exp.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "\n",
    "    # Loop through the batch to find examples of both labels\n",
    "    for sample_index in range(len(y)):\n",
    "        sample_label = int(y[sample_index].numpy()[0])  # Assuming binary classification\n",
    "\n",
    "        # Check if we already have examples for each label\n",
    "        if sample_label == 0 and not found_label_0:\n",
    "            found_label_0 = True\n",
    "            sample_frame_0 = X_frames[sample_index].numpy().astype(\"uint8\")\n",
    "            sample_micro_exp_0 = X_micro_exp[sample_index].numpy().astype(\"uint8\")\n",
    "\n",
    "        elif sample_label == 1 and not found_label_1:\n",
    "            found_label_1 = True\n",
    "            sample_frame_1 = X_frames[sample_index].numpy().astype(\"uint8\")\n",
    "            sample_micro_exp_1 = X_micro_exp[sample_index].numpy().astype(\"uint8\")\n",
    "\n",
    "        # Break loop once we have both examples\n",
    "        if found_label_0 and found_label_1:\n",
    "            break\n",
    "\n",
    "# Display images for both labels\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Display facial and micro-expression frames for label 0\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(sample_frame_0)\n",
    "plt.title(\"Facial Frame | Label: 0\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(sample_micro_exp_0)\n",
    "plt.title(\"Micro-Expression | Label: 0\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Display facial and micro-expression frames for label 1\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(sample_frame_1)\n",
    "plt.title(\"Facial Frame | Label: 1\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(sample_micro_exp_1)\n",
    "plt.title(\"Micro-Expression | Label: 1\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    min_lr=5e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_2 = Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = build_full_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "    optimizer=optimizer_2,\n",
    "    loss=\"mean_squared_logarithmic_error\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model_2.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=60,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model_2.evaluate(test_generator)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save(\"model_2_acc_9375_011124.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save_weights(\"model_2_weights_011124_acc_9375.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot loss and accuracy for training and validation sets\n",
    "def plot_history(history):\n",
    "    # Loss plot\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting the history of model_2\n",
    "plot_history(history_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            smoothed_points.append(smoothed_points[-1] * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "# Plot with smoothing\n",
    "def plot_history(history):\n",
    "    epochs = range(1, len(history.history['loss']) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, smooth_curve(history.history['loss']), label='Smoothed Training Loss')\n",
    "    plt.plot(epochs, smooth_curve(history.history['val_loss']), label='Smoothed Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss (Smoothed)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, smooth_curve(history.history['accuracy']), label='Smoothed Training Accuracy')\n",
    "    plt.plot(epochs, smooth_curve(history.history['val_accuracy']), label='Smoothed Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy (Smoothed)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true labels from the test generator\n",
    "y_true = np.concatenate([y for _, y in test_generator], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = model_2.predict(test_generator)\n",
    "\n",
    "test_prediction_labels = np.argmax(test_prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC-AUC Score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, test_prediction)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, test_prediction)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision, recall, _ = precision_recall_curve(y_true, test_prediction)\n",
    "\n",
    "# Plotting the Precision-Recall curve\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(recall, precision, color='blue', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misclassification rate for train and validation data\n",
    "train_misclassification = [1 - acc for acc in history_2.history['accuracy']]\n",
    "val_misclassification = [1 - val_acc for val_acc in history_2.history['val_accuracy']]\n",
    "\n",
    "# Plot misclassification rates\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(train_misclassification, label='Train Misclassification Rate')\n",
    "plt.plot(val_misclassification, label='Validation Misclassification Rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Misclassification Rate')\n",
    "plt.title('Misclassification Rate Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the history\n",
    "with open('history_2.pkl', 'wb') as f:\n",
    "    pickle.dump(history_2.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the history\n",
    "with open('../../saved/history_model_011124_acc_93.pkl', 'rb') as f:\n",
    "    history_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(history_2['lr'], label='Learning Rate', color='purple')\n",
    "plt.title('Learning Rate Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the last 10 epochs for zoom-in\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(history_2['val_loss'][-15:], label='Validation Loss (Last 15 Epochs)', color='orange')\n",
    "plt.title('Zoomed-in Validation Loss for Last 15 Epochs')\n",
    "plt.xlabel('Epochs (Last 15)')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the last 10 epochs for zoom-in\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(history_2['val_loss'][0:15], label='Validation Loss (First 15 Epochs)', color='orange')\n",
    "plt.title('Zoomed-in Validation Loss for First 15 Epochs')\n",
    "plt.xlabel('Epochs (First 15)')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 6))\n",
    "accuracy_diff = np.array(history_2['accuracy']) - np.array(history_2['val_accuracy'])\n",
    "plt.plot(accuracy_diff, label='Accuracy Difference (Train - Validation)', color='red')\n",
    "plt.title('Training and Validation Accuracy Difference Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy Difference')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 5))\n",
    "plt.plot(history_2['lr'], history_2['loss'], marker='o', color='purple')\n",
    "plt.title('Loss vs. Learning Rate')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size=3):\n",
    "    return np.convolve(data, np.ones(window_size) / window_size, mode='valid')\n",
    "\n",
    "plt.figure(figsize=(17, 5))\n",
    "plt.plot(moving_average(history_2['val_loss'], 5), label='Smoothed Validation Loss', color='orange')\n",
    "plt.plot(moving_average(history_2['val_accuracy'], 5), label='Smoothed Validation Accuracy', color='blue')\n",
    "plt.title('Smoothed Validation Loss and Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metric')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_accuracy_improvement = np.diff(history_2['accuracy'])\n",
    "plt.figure(figsize=(17, 5))\n",
    "plt.plot(epoch_accuracy_improvement, label='Epoch Accuracy Improvement', color='green')\n",
    "plt.axhline(0, color='red', linestyle='--', label='No Improvement Line')\n",
    "plt.title('Accuracy Improvement Per Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Improvement in Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(history_2['val_loss'])\n",
    "\n",
    "plt.figure(figsize=(17, 5))\n",
    "plt.plot(history_2['loss'], label='Training Loss', color='blue')\n",
    "plt.plot(history_2['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.axvline(best_epoch, color='red', linestyle='--', label=f'Best Epoch ({best_epoch})')\n",
    "plt.title('Training and Validation Loss with Best Epoch Marked')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 5))\n",
    "generalization_gap = np.array(history_2['val_loss']) - np.array(history_2['loss'])\n",
    "plt.plot(generalization_gap, color='purple', label='Generalization Gap (Validation - Training Loss)')\n",
    "plt.title('Generalization Gap Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss Difference')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss_slope = np.gradient(history_2['loss'])\n",
    "validation_loss_slope = np.gradient(history_2['val_loss'])\n",
    "\n",
    "plt.figure(figsize=(17, 5))\n",
    "plt.plot(training_loss_slope, label='Training Loss Slope', color='blue')\n",
    "plt.plot(validation_loss_slope, label='Validation Loss Slope', color='orange')\n",
    "plt.title('Training and Validation Loss Slope Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss Slope')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_loss_ratio = np.array(history_2['accuracy']) / (np.array(history_2['loss']) + 1e-8)\n",
    "plt.figure(figsize=(17, 5))\n",
    "plt.plot(accuracy_loss_ratio, color='green', label='Accuracy to Loss Ratio')\n",
    "plt.title('Accuracy to Loss Ratio Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy / Loss Ratio')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_accuracy = np.cumsum(history_2['accuracy'])\n",
    "cumulative_val_accuracy = np.cumsum(history_2['val_accuracy'])\n",
    "cumulative_loss = np.cumsum(history_2['loss'])\n",
    "cumulative_val_loss = np.cumsum(history_2['val_loss'])\n",
    "\n",
    "plt.figure(figsize=(17, 6))\n",
    "plt.plot(cumulative_accuracy, label='Cumulative Training Accuracy', color='blue')\n",
    "plt.plot(cumulative_val_accuracy, label='Cumulative Validation Accuracy', color='orange')\n",
    "plt.plot(cumulative_loss, label='Cumulative Training Loss', color='purple')\n",
    "plt.plot(cumulative_val_loss, label='Cumulative Validation Loss', color='red')\n",
    "plt.title('Cumulative Learning Progress Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cumulative Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5  # Adjust this based on your preferences\n",
    "accuracy_variance = pd.Series(history_2['accuracy']).rolling(window=window_size).var()\n",
    "val_accuracy_variance = pd.Series(history_2['val_accuracy']).rolling(window=window_size).var()\n",
    "loss_variance = pd.Series(history_2['loss']).rolling(window=window_size).var()\n",
    "val_loss_variance = pd.Series(history_2['val_loss']).rolling(window=window_size).var()\n",
    "\n",
    "plt.figure(figsize=(17, 6))\n",
    "plt.plot(accuracy_variance, label='Training Accuracy Variance', color='blue')\n",
    "plt.plot(val_accuracy_variance, label='Validation Accuracy Variance', color='orange')\n",
    "plt.plot(loss_variance, label='Training Loss Variance', color='purple')\n",
    "plt.plot(val_loss_variance, label='Validation Loss Variance', color='red')\n",
    "plt.title('Variance of Accuracy and Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Variance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midpoint = len(history_2['loss']) // 2\n",
    "epochs = list(range(len(history_2['loss'])))\n",
    "\n",
    "plt.figure(figsize=(17, 6))\n",
    "plt.plot(epochs[:midpoint], history_2['loss'][:midpoint], label='Early Phase Training Loss', color='blue')\n",
    "plt.plot(epochs[midpoint:], history_2['loss'][midpoint:], label='Later Phase Training Loss', color='purple')\n",
    "plt.plot(epochs[:midpoint], history_2['val_loss'][:midpoint], label='Early Phase Validation Loss', color='orange')\n",
    "plt.plot(epochs[midpoint:], history_2['val_loss'][midpoint:], label='Later Phase Validation Loss', color='red')\n",
    "plt.title('Early vs. Later Phase Loss Comparison')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gradient = np.gradient(history_2['lr'])\n",
    "accuracy_gradient = np.gradient(history_2['accuracy'])\n",
    "\n",
    "plt.figure(figsize=(17, 6))\n",
    "plt.plot(lr_gradient, label='Learning Rate Gradient', color='teal')\n",
    "plt.plot(accuracy_gradient, label='Accuracy Gradient', color='gold')\n",
    "plt.title('Learning Rate Gradient vs. Accuracy Gradient')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Gradient')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 5  # Choose the window size for smoothing\n",
    "\n",
    "plt.figure(figsize=(17, 6))\n",
    "plt.plot(pd.Series(history_2['accuracy']).rolling(window=window).mean(), label='Rolling Avg Training Accuracy', color='blue')\n",
    "plt.plot(pd.Series(history_2['val_accuracy']).rolling(window=window).mean(), label='Rolling Avg Validation Accuracy', color='orange')\n",
    "plt.plot(pd.Series(history_2['loss']).rolling(window=window).mean(), label='Rolling Avg Training Loss', color='purple')\n",
    "plt.plot(pd.Series(history_2['val_loss']).rolling(window=window).mean(), label='Rolling Avg Validation Loss', color='red')\n",
    "plt.title(f'Rolling Average of Accuracy and Loss (Window={window})')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metric')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_efficiency = np.array(history_2['accuracy']) / (np.array(history_2['lr']) + 1e-8)\n",
    "\n",
    "plt.figure(figsize=(17, 5))\n",
    "plt.plot(learning_efficiency, label='Learning Efficiency (Accuracy / Learning Rate)', color='magenta')\n",
    "plt.title('Learning Efficiency Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Learning Efficiency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_diff = np.array(history_2['val_loss']) - np.array(history_2['loss'])\n",
    "\n",
    "plt.figure(figsize=(17, 5))\n",
    "plt.plot(loss_diff, label='Validation Loss - Training Loss', color='crimson')\n",
    "plt.title('Difference Between Validation and Training Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss Difference')\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 5))\n",
    "plt.plot(history_2['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "plt.title('Validation Accuracy Over Epochs (Plateau Detection)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5  # Adjust the window for smoothing\n",
    "val_loss_smooth = pd.Series(history_2['val_loss']).rolling(window=window_size).mean()\n",
    "\n",
    "plt.figure(figsize=(17, 5))\n",
    "plt.plot(history_2['val_loss'], label='Validation Loss', color='salmon', alpha=0.3)\n",
    "plt.plot(val_loss_smooth, label=f'Smoothed Validation Loss (Window={window_size})', color='darkred')\n",
    "plt.title('Validation Loss with Moving Average (Overfitting Detection)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 6))\n",
    "plt.scatter(history_2['accuracy'], history_2['loss'], color='purple')\n",
    "plt.title('Correlation Between Training Accuracy and Loss')\n",
    "plt.xlabel('Training Accuracy')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_epochs = 20  # Adjust to check the initial epochs\n",
    "plt.figure(figsize=(17, 5))\n",
    "plt.plot(history_2['loss'][:early_epochs], label='Training Loss', color='blue')\n",
    "plt.plot(history_2['accuracy'][:early_epochs], label='Training Accuracy', color='green')\n",
    "plt.plot(history_2['val_loss'][:early_epochs], label='Validation Loss', color='orange')\n",
    "plt.plot(history_2['val_accuracy'][:early_epochs], label='Validation Accuracy', color='red')\n",
    "plt.title(f'Loss and Accuracy Stability in Early Epochs (First {early_epochs})')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metric')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_epochs = 20  # Adjust to check the initial epochs\n",
    "plt.figure(figsize=(17, 5))\n",
    "plt.plot(history_2['loss'][-early_epochs:], label='Training Loss', color='blue')\n",
    "plt.plot(history_2['accuracy'][-early_epochs:], label='Training Accuracy', color='green')\n",
    "plt.plot(history_2['val_loss'][-early_epochs:], label='Validation Loss', color='orange')\n",
    "plt.plot(history_2['val_accuracy'][-early_epochs:], label='Validation Accuracy', color='red')\n",
    "plt.title(f'Loss and Accuracy Stability in Early Epochs (Last {early_epochs})')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metric')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_change = np.diff(history_2['val_loss'])\n",
    "val_accuracy_change = np.diff(history_2['val_accuracy'])\n",
    "\n",
    "plt.figure(figsize=(17, 6))\n",
    "plt.plot(val_loss_change, label='Change in Validation Loss', color='purple')\n",
    "plt.plot(val_accuracy_change, label='Change in Validation Accuracy', color='green')\n",
    "plt.title('Epoch-to-Epoch Oscillations in Validation Loss and Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Change')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_change = np.diff(history_2['loss'])\n",
    "val_loss_change = np.diff(history_2['val_loss'])\n",
    "\n",
    "plt.figure(figsize=(17, 6))\n",
    "plt.plot(train_loss_change, label='Epoch-to-Epoch Change in Training Loss', color='blue')\n",
    "plt.plot(val_loss_change, label='Epoch-to-Epoch Change in Validation Loss', color='red')\n",
    "plt.title('Epoch-to-Epoch Change in Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss Change')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "\n",
    "The performance analysis of this deepfake detection model reveals its effectiveness, robustness, and overall stability across training, validation, and test phases. Key aspects of its performance, including accuracy, ROC-AUC score, and generalization gap, all reflect a model well-suited for detecting deepfakes with high reliability.\n",
    "\n",
    "### **1. Accuracy and Loss Metrics**\n",
    "\n",
    "The model achieved a training accuracy of 99.66% and validation accuracy of 94.10%, indicating an impressive capability to generalize well across unseen data. The test accuracy of 93.74% further supports the model's reliability, as it performs consistently across various datasets. The gradual decline in both training and validation loss, with a final training loss of 0.0601 and validation loss of 0.0884, suggests efficient learning without signs of overfitting.\n",
    "\n",
    "### **2. ROC-AUC and Precision-Recall Performance**\n",
    "\n",
    "The ROC-AUC score of 0.9786 indicates that the model is proficient in distinguishing between genuine and deepfake inputs. This high AUC value reflects a low false-positive rate, crucial for applications in sensitive fields such as media, security, and public trust. Similarly, the precision-recall curve showed robust precision and recall values, confirming the model's accuracy in deepfake detection and suggesting it can perform well even in varied real-world scenarios.\n",
    "\n",
    "### **3. Stability Over Epochs**\n",
    "\n",
    "An analysis of accuracy and loss trends over epochs reveals a strong stability in the modelâ€™s performance. The model effectively minimizes the generalization gap, seen in the similar decline patterns between training and validation loss curves. With an optimal stopping point around Epoch 26, it achieves high accuracy while minimizing validation loss. This point, identified through early stopping, ensures the model neither overfits nor underfits, optimizing both performance and training efficiency.\n",
    "\n",
    "### **4. Effective Learning Rate Adaptation**\n",
    "\n",
    "The adaptive learning rate helped the model achieve faster convergence. The ReduceLROnPlateau callback reduced the learning rate at key points, preventing oscillations in loss and allowing fine-grained updates in later epochs. This mechanism contributed significantly to maintaining high performance while ensuring stability in both accuracy and loss metrics. The gradual reductions in the learning rate allowed the model to reach and sustain its optimal state effectively.\n",
    "\n",
    "### **Final Thoughts**\n",
    "\n",
    "Overall, this deepfake detection model demonstrates an outstanding ability to detect manipulated content with high accuracy, minimal misclassifications, and efficient training dynamics. Given its solid performance across all tested metrics, it stands as a reliable solution for deepfake detection and has the potential to play a valuable role in combatting digital misinformation. With minor optimizations, this model could be further strengthened to handle more complex deepfake scenarios, marking an essential step forward in the ongoing fight against digital content manipulation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Face-Swap-Detection-Model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
